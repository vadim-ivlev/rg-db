{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export CSV files to Elasticsearch\n",
    "\n",
    "Change input_file_name, elastic_endpoint, index_name, max_number, batch_size variables here:\n",
    "\n",
    "To access notebook via ssh: `$ ssh -N -L 8888:localhost:8888 {user}@{server_ip}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import psycopg2\n",
    "import psycopg2.extras  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.getenv('RGPASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host=rg-db-prod port=5432 dbname=rgdb user=root password=rosgas2011 sslmode=disable\n"
     ]
    }
   ],
   "source": [
    "username = 'admin'\n",
    "password = os.getenv('RGPASS')\n",
    "DSN = os.getenv('RGDSN')\n",
    "DSN = 'host=rg-db-prod port=5432 dbname=rgdb user=root password=rosgas2011 sslmode=disable'\n",
    "print(DSN)\n",
    "# input directory\n",
    "source_dir = \"/home/jovyan/work/csv/\"\n",
    "\n",
    "# elastic endpoint\n",
    "elastic_endpoint = \"http://rg-corpus-caddy:8080/elasticsearch/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_batch(lines: list, elastic_endpoint:str, index_name:str):\n",
    "    \"\"\"saves batch of lines to database\"\"\"\n",
    "    data = '\\n'.join(lines)+'\\n'\n",
    "#     print(data)\n",
    "    return\n",
    "#     print('----------------------------------')\n",
    "    r = requests.post(f'{elastic_endpoint}{index_name}/_bulk', \n",
    "                      headers = {'Content-Type': 'application/x-ndjson; charset=UTF-8'}, \n",
    "                      auth=(username,password),\n",
    "                      data=data.encode('utf-8'))\n",
    "    try:\n",
    "        rjson=r.json()\n",
    "        if rjson.get('errors') is not False:\n",
    "            pprint(rjson)\n",
    "    except:\n",
    "        pprint(r)\n",
    "        \n",
    "#     lines.clear()\n",
    "    \n",
    "    \n",
    "def save_csv_file_to_elastic(input_file_name: str, elastic_endpoint:str, index_name:str,  max_number=0, batch_size=1000):\n",
    "    \"\"\"Saves CSV file to elasticsearch\n",
    "    - input_file_name - name of CSV file\n",
    "    - max_number - max number of records to save\n",
    "    - batch_size  - number of records in a batch \n",
    "    \"\"\"\n",
    "    # to process long fields in CSS file\n",
    "    csv.field_size_limit(sys.maxsize)\n",
    "    \n",
    "    \n",
    "    counter =0    # aka record id \n",
    "    lines =[]     # list of text lines to save\n",
    "    \n",
    "    with open(input_file_name) as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "\n",
    "        for row in reader:\n",
    "            if counter >= max_number: break\n",
    "            lines.append('{ \"index\" : {\"_id\" : \"'+str(counter)+'\" }}')\n",
    "            lines.append(json.dumps(row, ensure_ascii=False))\n",
    "            counter += 1\n",
    "            if counter % batch_size ==0:\n",
    "                print(f'counter = {counter}----------------')\n",
    "                save_batch(lines, elastic_endpoint, index_name)\n",
    "                lines.clear()\n",
    "                \n",
    "        print(f'counter = {counter}----------------')\n",
    "        save_batch(lines, elastic_endpoint, index_name)\n",
    "        lines.clear()\n",
    "\n",
    "def save_table_to_elastic(table_name: str, idname: str, elastic_endpoint:str, index_name:str,  max_number=0, batch_size=1000):\n",
    "    \"\"\"Saves table to elasticsearch\n",
    "    - table_name - name of postgres table\n",
    "    - max_number - max number of records to save\n",
    "    - batch_size  - number of records in a batch \n",
    "    \"\"\"\n",
    "    # to process long fields in CSS file\n",
    "    csv.field_size_limit(sys.maxsize)\n",
    "    \n",
    "    \n",
    "    counter =0    # aka record id \n",
    "    lines =[]     # list of text lines to save\n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        conn = psycopg2.connect(DSN)\n",
    "        with conn:\n",
    "            with conn.cursor('servercursor') as curs:\n",
    "                curs.execute(f\"SELECT {idname}, row_to_json(r,FALSE)::text FROM {table_name} r LIMIT {max_number}\")\n",
    "#                 curs.itersize=4000\n",
    "                for record in curs:\n",
    "                    if counter >= max_number: break\n",
    "                    elastic_id = counter if record[0] is None else record[0]\n",
    "                    lines.append('{\"index\" : {\"_id\" : \"'+str(elastic_id)+'\"}}')\n",
    "                    lines.append(record[1])\n",
    "                    counter += 1\n",
    "                    if counter % batch_size ==0:\n",
    "                        print(f'counter = {counter}----------------')\n",
    "                        save_batch(lines, elastic_endpoint, index_name)\n",
    "                        lines.clear()\n",
    "                print(f'counter = {counter}----------------')\n",
    "                save_batch(lines, elastic_endpoint, index_name)\n",
    "                lines.clear()\n",
    "       \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    finally:\n",
    "        conn.close()    \n",
    "    \n",
    "\n",
    "# save_table_to_elastic('rubrics','id', elastic_endpoint, 'rubrics', 16 , 3)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверки соединений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# проверки\n",
    "r = requests.get(elastic_endpoint, auth=(username, password))\n",
    "display(r.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт таблиц в Эластик "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter = 1153----------------\n",
      "CPU times: user 4.04 ms, sys: 6.93 ms, total: 11 ms\n",
      "Wall time: 23.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_table_to_elastic('rubrics', 'id', elastic_endpoint, 'rubrics', 2000 , 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter = 3053116----------------\n",
      "CPU times: user 2.37 s, sys: 285 ms, total: 2.66 s\n",
      "Wall time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_table_to_elastic('rubrics_objects', 'NULL', elastic_endpoint, 'rubrics_objects', 5000000 , 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dockertest Wall time: 21min 43s \n",
    "save_table_to_elastic('articles', 'obj_id', elastic_endpoint, 'articles', 1250000 , 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
